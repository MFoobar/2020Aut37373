{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"}},"source":["<br /><h1 style=\"font-family:Impact,Arial;font-size:70px;\">Air seen from desk compared to governments</h1>\n","<h2 style=\"font-family:Arial;\">Marco Foo</h2>\n","<h2 style=\"font-family:Arial;\">98044163</h2>\n","<p><small> 37373 Programming for Data Analysis</small></p>\n","<p><small><font color=MediumVioletRed>Autumn 2020</font></small>\n","</p>\n","<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />"]},{"cell_type":"markdown","metadata":{},"source":["# Abstract\n","\n","Air quality  \n","\n","Write a short (no more than 10 lines) summary of your project's topic and main goals."]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>1. Motivation</h1>\n","\n","Write a detailed description of the problem and the original goal(s) of the study. Explain why you were interested in this topic and the type of insight you were hoping to get from the data.\n","\n","Wanting to do something with the data that my air quality indicator gathers on a daily basis. I'm interested to see how the air in my day-to-day case of nearby a computer inside a home differs to generic readings of what the air quality is told to be outside."]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\"/>\n","<h1>2. The data</h1>\n","A clear description of the dataset(s) origin and a discussion of why it was chosen, as well as any restriction regarding the use, dissemination or modification of the data.\n","Note that wherever possible you should provide a link to the <b>unmodified, raw</b> data set.\n"]},{"cell_type":"markdown","metadata":{},"source":["My dataset is gathered within non-scientifically through the use of a Kaiterra Laser egg model NB500 placed on my workdesk in an open room.\n","\n","[insert floorplan here]\n","\n","The initial proposed dataset was mistakenly assumed to have the full recorded 894 days worth of air quality data recorded, however it was later found out to only contain 10000 records. Such that a bunch of datasets had to be downloaded to get the full recorded air quality data. \n","\n","What's recorded my datasets:\n","\n","\"Time Point\" - Date format of 'YYYY/MM/DD HH:MM'\n","\n","\"PM10 (µg/m³)\" - Integer recording of PM10\n","\n","\"PM2.5 (µg/mÂ³)\" - Integer recording of PM2.5\n","\n","\"humidity (%)\" - Float recording of the humidity to 2 decimal places\n","\n","\"temp (C)\" - Float recording of the temperature to 2 decimal places\n","\n","\"Overall Index (US)\" - AQI recording according to the US standard\n","\n","<p>\n","The openly avaliable datasets I used to compare with my dataset are found within NSW Govt website with varying options of data output, <a href=\"https://www.dpie.nsw.gov.au/air-quality/search-for-and-download-air-quality-data\">here</a>.\n","</p>\n","Specifically, I choose to output multiple differing datasets to draw comparisons with my original datasets.\n","\n","Hourly AQI averages for the date range of 2019 January 1st to 2020 June 15th for both Prospect and North Parramatta site indexes. \n","$#@$#$#for all of the possible sydney-north-west data collection sites. Vineyard's data is all empty, so it's excluded. \n","Note, this AQI \n","\n","Hourly reported PM2.5, PM10, Windspeed, wind direction, air temperature, relative humidity, global solar radiation and rainfall for the date range of 2019 January 1st to 2020 June 15th for Prospect, and North Parramatta individually. They're seperate datasets due to the query not allowing the combination due to it's size. \n","$#$#$for all possible sydney-north-west data collection sites excluding the empty Vineyard option, individually.\n","<p>\n","This brings the question of the differing AQI measurements, and whether the recorded AQI is using the US standard or another. \n","The <a href=\"https://www.environment.nsw.gov.au/topics/air/understanding-air-quality-data/air-quality-index\">overview of the Australian AQI</a>,\n","<a href=\"https://aqicn.org/faq/2014-09-06/australian-air-quality-comparison-with-the-us-epa-aqi-scale/\">US and Australian AQI comparison</a> and <a href =\"https://www.legislation.gov.au/Details/F2016C00215\">government legislation</a> helped with discerning each of the scales. An unsolved problem I encountered researching the National Environment Protection Measure (NEPM) standard, i.e. the standard used in NSW, is that I couldn't find any hard formula other than ranges. As the US AQI standard is widely known and avaliable, as seen in <a href =\"https://forum.airnowtech.org/t/the-aqi-equation/169\">here</a>. If down, image in the appendix.\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>3. Data preparation</h1>\n","\n","Code and comments on how the raw data is put in a usable form (i.e., how you go from the raw data set(s) to the dataframe you are using for the analysis).\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"code","execution_count":241,"metadata":{},"outputs":[],"source":["#Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib as mpt\n","import seaborn as sns\n","%matplotlib inline\n","from pathlib import Path\n","import os"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                  Time  PM10  PM2.5  Humidity   Temp  USAQI HighestPMType\n0  2018-11-15 23:22:00   2.0    2.0     24.44  28.99    8.0         PM2.5\n1  2018-11-15 23:30:00   3.0    3.0     25.33  28.02   13.0         PM2.5\n2  2018-11-15 23:31:00   4.0    4.0     25.50  27.93   17.0         PM2.5\n3  2018-11-15 23:32:00   3.0    1.0     26.08  27.88    4.0         PM2.5\n4  2018-11-15 23:33:00   3.0    3.0     25.99  27.85   13.0         PM2.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>PM10</th>\n      <th>PM2.5</th>\n      <th>Humidity</th>\n      <th>Temp</th>\n      <th>USAQI</th>\n      <th>HighestPMType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-11-15 23:22:00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>24.44</td>\n      <td>28.99</td>\n      <td>8.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-11-15 23:30:00</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>25.33</td>\n      <td>28.02</td>\n      <td>13.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-11-15 23:31:00</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>25.50</td>\n      <td>27.93</td>\n      <td>17.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-11-15 23:32:00</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>26.08</td>\n      <td>27.88</td>\n      <td>4.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-11-15 23:33:00</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>25.99</td>\n      <td>27.85</td>\n      <td>13.0</td>\n      <td>PM2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":242}],"source":["#MyDatasets\n","#Archaic dataset names as seen in the MyData_org zip was later manually changed so that it follows the scheme of 'YYYYMMDD HHMMtoYYYYMMDD HHMM' denoting the earliest to latest point of data gathered\n","mPath = Path('../myData')\n","list_my_df_fullnames = [item.name for item in sorted(mPath.glob('*.csv'))]\n","list_my_df = []\n","for file in list_my_df_fullnames:\n","    path = Path(mPath, file)\n","    df_myData = pd.read_csv(path, parse_dates=True, infer_datetime_format=True, header=7, names=['Time', 'PM10', 'PM2.5', 'Humidity', 'Temp', 'USAQI', 'HighestPMType'])\n","    list_my_df.append(df_myData)\n","df_allmyData = pd.concat(list_my_df, ignore_index=True)\n","df_allmyData.head()"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Time             336460\nPM10             336392\nPM2.5            336392\nHumidity         336460\nTemp             336460\nUSAQI            336392\nHighestPMType    336392\ndtype: int64\n                     Time  PM10  PM2.5  Humidity   Temp  USAQI HighestPMType\n9760  2019-01-02 18:35:00  68.0   58.0     24.49  22.89  152.0         PM2.5\n9761  2019-01-02 18:36:00  66.0   57.0     24.50  22.90  152.0         PM2.5\n9762  2019-01-02 18:37:00  67.0   59.0     24.39  22.91  153.0         PM2.5\n9763  2019-01-02 18:38:00  61.0   55.0     24.34  22.92  149.0         PM2.5\n9764  2019-01-02 18:39:00  68.0   60.0     24.33  22.93  153.0         PM2.5\n...                   ...   ...    ...       ...    ...    ...           ...\n9828  2019-01-02 18:35:00  68.0   58.0     24.49  22.89  152.0         PM2.5\n9829  2019-01-02 18:36:00  66.0   57.0     24.50  22.90  152.0         PM2.5\n9830  2019-01-02 18:37:00  67.0   59.0     24.39  22.91  153.0         PM2.5\n9831  2019-01-02 18:38:00  61.0   55.0     24.34  22.92  149.0         PM2.5\n9832  2019-01-02 18:39:00  68.0   60.0     24.33  22.93  153.0         PM2.5\n\n[73 rows x 7 columns]\n"}],"source":["# We've got 68 minutes worth of unrecorded air quality statistics, time to find those rows and take them out. As well as the duplicated data that was a consequence of how I had to gather the data from Kaiterra's servers.\n","\n","print(df_allmyData.count())\n","print(df_allmyData[9760:9833])\n","\n","# Looks good, time for the data types and go for rolling averages per hour, similar to the NSW dataset\n","\n","df_allmyData = df_allmyData.drop_duplicates()\n","df_allmyData = df_allmyData.dropna()\n","print(df_allmyData.count())\n","print(df_allmyData[9760:9833])\n","print(df_allmyData.dtypes)"]},{"cell_type":"code","execution_count":251,"metadata":{},"outputs":[],"source":["# list_my_df_names_early = [item[0:13] for item in list_my_df_fullnames]\n","# list_my_df_names_latest = [item[17:30] for item in list_my_df_fullnames]\n","# rMy_df = pd.read_csv(\"../myData/20181115 2322 to 20190102 1847.csv\", parse_dates=True, infer_datetime_format=True, header=7)\n","# list_my_df[1].head()\n","# 'Time Point', 'PM10 (µg/m³)', 'PM2.5 (µg/m³)', 'humidity (%)', 'temp (C)', 'Overall Index (US)', 'Primary Pollutant'\n","# 'Time', 'PM10', 'PM2.5', 'Humidity', 'Temp', 'USAQI', 'HighestPMType'\n","# my_df_header\n","# Not Working right annoyingly #my_df_header = str(pd.read_csv(\"../myData/20181115 2322 to 20190102 1847.csv\", header=7, nrows=0).columns)\n","\n","# Converting types\n","df_allmyData['Time'] = pd.to_datetime(df_allmyData['Time'], infer_datetime_format=True)\n","# df_allmyData['PM10'] = df_allmyData['PM10'].astype('int64')\n","# df_allmyData['PM2.5'] = df_allmyData['PM2.5'].astype('int64')\n","# df_allmyData['USAQI'] = df_allmyData['USAQI'].astype('int64')\n","df_allmyData['HighestPMType'] = df_allmyData['HighestPMType'].astype('category')\n","# print(df_allmyData.dtypes)\n","# df_allmyData.head()\n"]},{"cell_type":"code","execution_count":248,"metadata":{},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"invalid on specified as 0        2018-11-15 23:22:00\n1        2018-11-15 23:30:00\n2        2018-11-15 23:31:00\n3        2018-11-15 23:32:00\n4        2018-11-15 23:33:00\n                 ...        \n336455   2020-06-14 18:40:32\n336456   2020-06-14 18:41:32\n336457   2020-06-14 18:42:32\n336458   2020-06-14 18:43:32\n336459   2020-06-14 18:44:32\nName: Time, Length: 292623, dtype: datetime64[ns], must be a column (of DataFrame), an Index or None","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-248-d2d9ec7ffa72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# df_avgmyData.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# df_allmyData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_allmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPM10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'60m'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_allmyData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM10'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mF:\\Applicaiont\\AnadondaInstall2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mrolling\u001b[1;34m(self, window, min_periods, center, win_type, on, axis, closed)\u001b[0m\n\u001b[0;32m  10382\u001b[0m                 \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10383\u001b[0m                 \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10384\u001b[1;33m                 \u001b[0mclosed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10385\u001b[0m             )\n\u001b[0;32m  10386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mF:\\Applicaiont\\AnadondaInstall2\\lib\\site-packages\\pandas\\core\\window\\rolling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, window, min_periods, center, win_type, axis, on, closed, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwin_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numba_func_cache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mF:\\Applicaiont\\AnadondaInstall2\\lib\\site-packages\\pandas\\core\\window\\rolling.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m         \u001b[1;31m# we allow rolling on a datetimelike index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1832\u001b[1;33m         if (self.obj.empty or self.is_datetimelike) and isinstance(\n\u001b[0m\u001b[0;32m   1833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDateOffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m         ):\n","\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n","\u001b[1;32mF:\\Applicaiont\\AnadondaInstall2\\lib\\site-packages\\pandas\\core\\window\\rolling.py\u001b[0m in \u001b[0;36mis_datetimelike\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m         return isinstance(\n\u001b[1;32m-> 1806\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDatetimeIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCTimedeltaIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCPeriodIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1807\u001b[0m         )\n\u001b[0;32m   1808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n","\u001b[1;32mF:\\Applicaiont\\AnadondaInstall2\\lib\\site-packages\\pandas\\core\\window\\rolling.py\u001b[0m in \u001b[0;36m_on\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1823\u001b[1;33m                 \u001b[1;34mf\"invalid on specified as {self.on}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m                 \u001b[1;34m\"must be a column (of DataFrame), an Index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m                 \u001b[1;34m\"or None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: invalid on specified as 0        2018-11-15 23:22:00\n1        2018-11-15 23:30:00\n2        2018-11-15 23:31:00\n3        2018-11-15 23:32:00\n4        2018-11-15 23:33:00\n                 ...        \n336455   2020-06-14 18:40:32\n336456   2020-06-14 18:41:32\n336457   2020-06-14 18:42:32\n336458   2020-06-14 18:43:32\n336459   2020-06-14 18:44:32\nName: Time, Length: 292623, dtype: datetime64[ns], must be a column (of DataFrame), an Index or None"]}],"source":["# df_avgmyData = pd.DataFrame(index=df_allmyData['Time'])\n","\n","# df_avgmyData['PM10'] = (\n","#     df_allmyData\n","#     .assign(PM10=df_allmyData.rolling(window='60m', on=df_allmyData['Time'])['PM10'].mean())\n","#     .groupby(df_allmyData['Time'].dt.date)['PM10']\n","#     .last())\n","# df_avgmyData.head()\n","# df_allmyData\n","print(df_allmyData.PM10.rolling(window='60m', on=df_allmyData['Time'])['PM10'].mean())"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"Time Point            datetime64[ns]\nPM10 (µg/m³)                 float64\nPM2.5 (µg/m³)                float64\nhumidity (%)                 float64\ntemp (C)                     float64\nOverall Index (US)           float64\nPrimary Pollutant             object\ndtype: object"},"metadata":{},"execution_count":89}],"source":["df_allmyData[0:10].dtypes"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Public avaliable datasets\n","# rParra_df = pd.read_excel(\"../govtData/nparra.xlsx\", 'worksheet1')\n","# rProspect_df = pd.read_excel(\"../govtData/prospect.xlsx\", 'worksheet1')\n","rParra_df = pd.read_excel(\"../govtData/nparra_org.xls\", 'worksheet1')\n","rProspect_df = pd.read_excel(\"../govtData/prospect_org.xls\", 'worksheet1')"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>4. Exploratory data analysis</h1>\n","\n","This is the main part of the project. Include code, plots, and detailed explanation of your analysis of the data. Be sure to include enough detail so that anyone can follow and understand what you are doing.\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Questions to ask</h2>\n","<li> What's a week look like? Maybe heatmaps? </li>\n","<li> How does each of the PM stats compare to eachother? </li>\n","<li> How does the meterological stats compare to eachother? </li>\n","<li> Does wind, rain or other meterological measures have a correlation with the air quality indicators? </li>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>5. Results/Insights</h1>\n","\n","Discuss any non-trivial result or insight into the problem stemming from your analysis.\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>6. In hindsight...</h1>\n","\n","In this section you should reflect on your work and what you've learned. In particular you should include:\n","\n","<ul>\n","    <li> a discussion of the most challenging aspect of the data analysis and if/how you overcame the challenge.</li>\n","    <li> a discussion of any programming technique and/or reference you found particularly useful or helpful for your project.</li>\n","    <li> an assessment of the outcome of the study in relation to the original goals (i.e., have the goals been reached, or did you have to reassess the goals during the project, and if so why?).</li>\n","    <li> a discussion of what new, or surprising knowledge or insight into the problem you've gained by conducting the study.</li>\n","    <li> a discussion of whether you would approach the problem differently if given an opportunity to redo the work, and any advice they would give to someone who would want to work on a similar problem.</li>\n","    <li> a discussion of how your analysis could be improved or extended in future work.</li>\n","\n","</ul>"]},{"cell_type":"markdown","metadata":{},"source":["In hindsight, the time spent manually changing the filenames was wasted due to how data was read. "]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>Appendix</h1>\n","<p> Image of US AQI calculation </p>\n","<a href=\"https://forum.airnowtech.org/t/the-aqi-equation/169\"><img src=\"https://puu.sh/FWnlz/f37ea1e65d.png\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["The adventure into the air quality data I've gathered. \n","My non-scientific and possible real-world-case approach to how I went through the analysais of my gathered dataset.\n","\n","For context, this dataset is gathered by a Kaiterra LaserEgg model LE-200 that is placed on my work desk at my home. Not in scientific conditions, as the layout of my house can describe this [Insert quick layout]\n","\n"," "]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.7-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":2}