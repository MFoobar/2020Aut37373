{"cells":[{"cell_type":"markdown","metadata":{"slideshow":{"slide_type":"slide"}},"source":["<br /><h1 style=\"font-family:Impact,Arial;font-size:70px;\">Air seen from desk compared to governments</h1>\n","<h2 style=\"font-family:Arial;\">Marco Foo</h2>\n","<h2 style=\"font-family:Arial;\">98044163</h2>\n","<p><small> 37373 Programming for Data Analysis</small></p>\n","<p><small><font color=MediumVioletRed>Autumn 2020</font></small>\n","</p>\n","<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />"]},{"cell_type":"markdown","metadata":{},"source":["# Abstract\n","\n","Air quality  \n","\n","Write a short (no more than 10 lines) summary of your project's topic and main goals."]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>1. Motivation</h1>\n","\n","Write a detailed description of the problem and the original goal(s) of the study. Explain why you were interested in this topic and the type of insight you were hoping to get from the data.\n","\n","Wanting to do something with the data that my air quality indicator gathers on a daily basis. I'm interested to see how the air in my day-to-day case of nearby a computer inside a home differs to generic readings of what the air quality is told to be outside."]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\"/>\n","<h1>2. The data</h1>\n","A clear description of the dataset(s) origin and a discussion of why it was chosen, as well as any restriction regarding the use, dissemination or modification of the data.\n","Note that wherever possible you should provide a link to the <b>unmodified, raw</b> data set.\n"]},{"cell_type":"markdown","metadata":{},"source":["My dataset is gathered within non-scientifically through the use of a Kaiterra Laser egg model NB500 placed on my workdesk in an open room.\n","\n","[insert floorplan here]\n","\n","The initial proposed dataset was mistakenly assumed to have the full recorded 894 days worth of air quality data recorded, however it was later found out to only contain 10000 records. Such that a bunch of datasets had to be downloaded to get the full recorded air quality data. \n","\n","What's recorded my datasets:\n","\n","\"Time Point\" - Date format of 'YYYY/MM/DD HH:MM'\n","\n","\"PM10 (µg/m³)\" - Integer recording of PM10\n","\n","\"PM2.5 (µg/mÂ³)\" - Integer recording of PM2.5\n","\n","\"humidity (%)\" - Float recording of the humidity to 2 decimal places\n","\n","\"temp (C)\" - Float recording of the temperature to 2 decimal places\n","\n","\"Overall Index (US)\" - AQI recording according to the US standard\n","\n","<p>\n","The openly avaliable datasets I used to compare with my dataset are found within NSW Govt website with varying options of data output, <a href=\"https://www.dpie.nsw.gov.au/air-quality/search-for-and-download-air-quality-data\">here</a>.\n","</p>\n","Specifically, I choose to output multiple differing datasets to draw comparisons with my original datasets.\n","\n","Hourly AQI averages for the date range of 2019 January 1st to 2020 June 15th for both Prospect and North Parramatta site indexes. \n","$#@$#$#for all of the possible sydney-north-west data collection sites. Vineyard's data is all empty, so it's excluded. \n","Note, this AQI \n","\n","Hourly reported PM2.5, PM10, Windspeed, wind direction, air temperature, relative humidity, global solar radiation and rainfall for the date range of 2019 January 1st to 2020 June 15th for Prospect, and North Parramatta individually. They're seperate datasets due to the query not allowing the combination due to it's size. \n","$#$#$for all possible sydney-north-west data collection sites excluding the empty Vineyard option, individually.\n","<p>\n","This brings the question of the differing AQI measurements, and whether the recorded AQI is using the US standard or another. \n","The <a href=\"https://www.environment.nsw.gov.au/topics/air/understanding-air-quality-data/air-quality-index\">overview of the Australian AQI</a>,\n","<a href=\"https://aqicn.org/faq/2014-09-06/australian-air-quality-comparison-with-the-us-epa-aqi-scale/\">US and Australian AQI comparison</a> and <a href =\"https://www.legislation.gov.au/Details/F2016C00215\">government legislation</a> helped with discerning each of the scales. An unsolved problem I encountered researching the National Environment Protection Measure (NEPM) standard, i.e. the standard used in NSW, is that I couldn't find any hard formula other than ranges. As the US AQI standard is widely known and avaliable, as seen in <a href =\"https://forum.airnowtech.org/t/the-aqi-equation/169\">here</a>. If down, image in the appendix.\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>3. Data preparation</h1>\n","\n","Code and comments on how the raw data is put in a usable form (i.e., how you go from the raw data set(s) to the dataframe you are using for the analysis).\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"code","execution_count":407,"metadata":{},"outputs":[],"source":["# df_avgmyData = pd.DataFrame(index=df_allmyData['Time'])\n","# print(df_allmyData.rolling(window=60)['PM10'].mean())\n","# print(df_allmyData.rolling(window=60, min_periods=1)['PM10'].mean())\n","# df_allmyData[:292581:-1]\n","    # df_allmyData\n","    # .assign(PM10_avg=df_allmyData.rolling(window=60, min_periods=1)['PM10'].mean())\n","    # .groupby(df_allmyData['Time'].dt.date)['PM10_avg']\n","    # .last())\n","# df_allmyData[:292581:-1]\n","# df_allmyData.head()\n","\n","# list_my_df_names_early = [item[0:13] for item in list_my_df_fullnames]\n","# list_my_df_names_latest = [item[17:30] for item in list_my_df_fullnames]\n","# rMy_df = pd.read_csv(\"../myData/20181115 2322 to 20190102 1847.csv\", parse_dates=True, infer_datetime_format=True, header=7)\n","# list_my_df[1].head()\n","# 'Time Point', 'PM10 (µg/m³)', 'PM2.5 (µg/m³)', 'humidity (%)', 'temp (C)', 'Overall Index (US)', 'Primary Pollutant'\n","# 'Time', 'PM10', 'PM2.5', 'Humidity', 'Temp', 'USAQI', 'HighestPMType'\n","# my_df_header\n","# Not Working right annoyingly #my_df_header = str(pd.read_csv(\"../myData/20181115 2322 to 20190102 1847.csv\", header=7, nrows=0).columns)\n","\n","# df_nParra_org = pd.read_excel(list_govt_df_path[1], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[7:14], index_col=1)\n","# df_prospect_org = pd.read_excel(list_govt_df_path[2], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[15:21], index_col=1)\n","# df_richmond_org = pd.read_excel(list_govt_df_path[3], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[22:28], index_col=1)\n","# df_rouseHill_org = pd.read_excel(list_govt_df_path[4], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[29:35], index_col=1)\n","# df_stMarys_org = pd.read_excel(list_govt_df_path[5], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[36:42], index_col=True)\n","# df_westSydAQI_noVinyard_org = pd.read_excel(list_govt_df_path[7], header=2, parse_dates=[['Date', 'Time']], names=list_govt_headings[50:56], ignore_index=True)\n","\n","# def droppingNaa(dataset):\n","#     lenBefore = len(dataset)\n","#     dataset.dropna(dataset)\n","#     lenAfter = len(dataset)\n","#     print('Dropped ' + str(lenBefore - lenAfter) + ' Naas from ' + str(dataset))\n","# def droppingDupes(dataset, subset='Time', ignore_index=True):\n","#     lenBefore = len(dataset)\n","#     dataset.drop_duplicates(subset=subset, ignore_index=ignore_index)\n","#     lenAfter = len(dataset)\n","#     print('Dropped ' + str(lenBefore - lenAfter) + ' Dupes from ' + str(dataset))\n","# droppingDupes(df_allmyData)\n","# droppingNaa(df_allmyData)\n","\n","# list_govt_df = []\n","# for file in list_govt_file_names:\n","#     path = Path(gPath, file)\n","#     df_govtData = df_govtData.merge(df_govtData)\n","#     df_govtData = pd.read_excel(path, header=2)\n","# # df_govtData = pd.merge(list_govt_df)\n","# print(df_govtData.head())\n","# print(df_govtData.tail())"]},{"cell_type":"code","execution_count":468,"metadata":{},"outputs":[],"source":["#Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib as mpt\n","import seaborn as sns\n","%matplotlib inline\n","from pathlib import Path\n","import os\n","import re"]},{"cell_type":"code","execution_count":610,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                  Time  PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType\n0  2018-11-15 23:22:00   2.0    2.0     24.44  28.99     8.0         PM2.5\n1  2018-11-15 23:30:00   3.0    3.0     25.33  28.02    13.0         PM2.5\n2  2018-11-15 23:31:00   4.0    4.0     25.50  27.93    17.0         PM2.5\n3  2018-11-15 23:32:00   3.0    1.0     26.08  27.88     4.0         PM2.5\n4  2018-11-15 23:33:00   3.0    3.0     25.99  27.85    13.0         PM2.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>PM10</th>\n      <th>PM2.5</th>\n      <th>Humidity</th>\n      <th>Temp</th>\n      <th>US_AQI</th>\n      <th>HighestPMType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-11-15 23:22:00</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>24.44</td>\n      <td>28.99</td>\n      <td>8.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-11-15 23:30:00</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>25.33</td>\n      <td>28.02</td>\n      <td>13.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-11-15 23:31:00</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>25.50</td>\n      <td>27.93</td>\n      <td>17.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-11-15 23:32:00</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>26.08</td>\n      <td>27.88</td>\n      <td>4.0</td>\n      <td>PM2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-11-15 23:33:00</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>25.99</td>\n      <td>27.85</td>\n      <td>13.0</td>\n      <td>PM2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":610}],"source":["# MyDatasets\n","# Archaic dataset names as seen in the MyData_org zip was later manually changed so that it follows the scheme of 'YYYYMMDD HHMMtoYYYYMMDD HHMM' denoting the earliest to latest point of data gathered\n","mPath = Path('../myData')\n","list_my_df_fullnames = [item.name for item in sorted(mPath.glob('*.csv'))]\n","list_my_df = []\n","for file in list_my_df_fullnames:\n","    path = Path(mPath, file)\n","    df_myData = pd.read_csv(path, header=7, names=['Time', 'PM10', 'PM2.5', 'Humidity', 'Temp', 'US_AQI', 'HighestPMType'])\n","    list_my_df.append(df_myData)\n","df_allmyData = pd.concat(list_my_df, ignore_index=True)\n","df_allmyData.head()"]},{"cell_type":"code","execution_count":612,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Time             336460\nPM10             336392\nPM2.5            336392\nHumidity         336460\nTemp             336460\nUS_AQI           336392\nHighestPMType    336392\ndtype: int64\n                     Time  PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType\n9760  2019-01-02 18:35:00  68.0   58.0     24.49  22.89   152.0         PM2.5\n9761  2019-01-02 18:36:00  66.0   57.0     24.50  22.90   152.0         PM2.5\n9762  2019-01-02 18:37:00  67.0   59.0     24.39  22.91   153.0         PM2.5\n9763  2019-01-02 18:38:00  61.0   55.0     24.34  22.92   149.0         PM2.5\n9764  2019-01-02 18:39:00  68.0   60.0     24.33  22.93   153.0         PM2.5\n...                   ...   ...    ...       ...    ...     ...           ...\n9828  2019-01-02 18:35:00  68.0   58.0     24.49  22.89   152.0         PM2.5\n9829  2019-01-02 18:36:00  66.0   57.0     24.50  22.90   152.0         PM2.5\n9830  2019-01-02 18:37:00  67.0   59.0     24.39  22.91   153.0         PM2.5\n9831  2019-01-02 18:38:00  61.0   55.0     24.34  22.92   149.0         PM2.5\n9832  2019-01-02 18:39:00  68.0   60.0     24.33  22.93   153.0         PM2.5\n\n[73 rows x 7 columns]\nTime             292623\nPM10             292623\nPM2.5            292623\nHumidity         292623\nTemp             292623\nUS_AQI           292623\nHighestPMType    292623\ndtype: int64\n                     Time  PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType\n9760  2019-01-02 18:35:00  68.0   58.0     24.49  22.89   152.0         PM2.5\n9761  2019-01-02 18:36:00  66.0   57.0     24.50  22.90   152.0         PM2.5\n9762  2019-01-02 18:37:00  67.0   59.0     24.39  22.91   153.0         PM2.5\n9763  2019-01-02 18:38:00  61.0   55.0     24.34  22.92   149.0         PM2.5\n9764  2019-01-02 18:39:00  68.0   60.0     24.33  22.93   153.0         PM2.5\n...                   ...   ...    ...       ...    ...     ...           ...\n9828  2019-09-05 02:46:03   7.0    7.0     58.87  17.56    29.0         PM2.5\n9829  2019-09-05 02:47:02   9.0    9.0     58.89  17.54    38.0         PM2.5\n9830  2019-09-05 02:48:02   7.0    7.0     59.08  17.52    29.0         PM2.5\n9831  2019-09-05 02:49:02   9.0    9.0     63.93  17.63    38.0         PM2.5\n9832  2019-09-05 02:50:02   7.0    7.0     60.36  17.74    29.0         PM2.5\n\n[73 rows x 7 columns]\nTime              object\nPM10             float64\nPM2.5            float64\nHumidity         float64\nTemp             float64\nUS_AQI           float64\nHighestPMType     object\ndtype: object\n"}],"source":["# We've got 68 minutes worth of unrecorded air quality statistics, time to find those rows and take them out. As well as the duplicated data that was a consequence of how I had to gather the data from Kaiterra's servers.\n","\n","print(df_allmyData.count())\n","print(df_allmyData[9760:9833])\n","\n","df_allmyData = df_allmyData.drop_duplicates(subset='Time', ignore_index=True)\n","df_allmyData = df_allmyData.dropna()\n","\n","print(df_allmyData.count())\n","print(df_allmyData[9760:9833])\n","print(df_allmyData.dtypes)"]},{"cell_type":"markdown","metadata":{},"source":["Looks good, time for the data types and go for rolling averages per hour, similar to the NSW dataset"]},{"cell_type":"code","execution_count":613,"metadata":{},"outputs":[],"source":["# Converting types\n","df_allmyData['Time'] = pd.to_datetime(df_allmyData['Time'])\n","df_allmyData['PM10'] = df_allmyData['PM10'].astype('int64')\n","df_allmyData['PM2.5'] = df_allmyData['PM2.5'].astype('int64')\n","df_allmyData['US_AQI'] = df_allmyData['US_AQI'].astype('int64')\n","df_allmyData['HighestPMType'] = df_allmyData['HighestPMType'].astype('category')"]},{"cell_type":"code","execution_count":614,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"PM10                int64\nPM2.5               int64\nHumidity          float64\nTemp              float64\nUS_AQI              int64\nHighestPMType    category\nPM10_avg          float64\nPM2.5_avg         float64\nUS_AQI_avg        float64\ndtype: object\n                     PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType  \\\nTime                                                                      \n2018-11-15 23:22:00     2      2     24.44  28.99       8         PM2.5   \n2018-11-15 23:30:00     3      3     25.33  28.02      13         PM2.5   \n2018-11-15 23:31:00     4      4     25.50  27.93      17         PM2.5   \n2018-11-15 23:32:00     3      1     26.08  27.88       4         PM2.5   \n2018-11-15 23:33:00     3      3     25.99  27.85      13         PM2.5   \n\n                     PM10_avg  PM2.5_avg  US_AQI_avg  \nTime                                                  \n2018-11-15 23:22:00       2.0        2.0    8.000000  \n2018-11-15 23:30:00       2.5        2.5   10.500000  \n2018-11-15 23:31:00       3.0        3.0   12.666667  \n2018-11-15 23:32:00       3.0        2.5   10.500000  \n2018-11-15 23:33:00       3.0        2.6   11.000000  \n                     PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType  \\\nTime                                                                      \n2019-01-02 18:35:00    68     58     24.49  22.89     152         PM2.5   \n2019-01-02 18:36:00    66     57     24.50  22.90     152         PM2.5   \n2019-01-02 18:37:00    67     59     24.39  22.91     153         PM2.5   \n2019-01-02 18:38:00    61     55     24.34  22.92     149         PM2.5   \n2019-01-02 18:39:00    68     60     24.33  22.93     153         PM2.5   \n2019-01-02 18:40:00    63     56     24.28  22.94     151         PM2.5   \n2019-01-02 18:41:00    63     55     24.25  22.95     149         PM2.5   \n2019-01-02 18:42:00    68     58     24.19  22.96     152         PM2.5   \n2019-01-02 18:43:00    61     56     24.19  22.96     151         PM2.5   \n2019-01-02 18:44:00    63     56     24.16  22.97     151         PM2.5   \n2019-01-02 18:45:00    65     56     24.16  22.97     151         PM2.5   \n2019-01-02 18:46:00    59     54     24.17  22.97     147         PM2.5   \n2019-01-02 18:47:00    64     55     24.18  22.98     149         PM2.5   \n2019-09-05 01:51:10    16     14     50.35  20.60      55         PM2.5   \n2019-09-05 01:52:10    16     16     51.77  20.22      59         PM2.5   \n2019-09-05 01:53:10    16     15     54.09  19.53      57         PM2.5   \n2019-09-05 01:54:10    17     16     54.51  19.44      59         PM2.5   \n2019-09-05 01:55:10    15     15     54.79  19.40      57         PM2.5   \n2019-09-05 01:56:09    15     13     54.75  19.41      53         PM2.5   \n2019-09-05 01:57:09    15     14     54.84  19.40      55         PM2.5   \n2019-09-05 01:58:09    16     15     54.72  19.41      57         PM2.5   \n2019-09-05 01:59:09    18     17     55.41  19.43      61         PM2.5   \n2019-09-05 02:00:09    15     15     54.54  19.39      57         PM2.5   \n2019-09-05 02:01:09    15     14     54.76  19.25      55         PM2.5   \n2019-09-05 02:02:09    14     13     55.01  19.12      53         PM2.5   \n2019-09-05 02:03:09    19     17     55.31  19.00      61         PM2.5   \n2019-09-05 02:04:09    15     14     55.58  18.89      55         PM2.5   \n2019-09-05 02:05:08    14     14     55.83  18.78      55         PM2.5   \n2019-09-05 02:06:08    14     13     56.04  18.70      53         PM2.5   \n2019-09-05 02:07:08    14     13     56.20  18.63      53         PM2.5   \n2019-09-05 02:08:08    14     12     56.33  18.57      50         PM2.5   \n2019-09-05 02:09:08    14     13     56.48  18.52      53         PM2.5   \n2019-09-05 02:10:08    13     12     56.61  18.47      50         PM2.5   \n2019-09-05 02:11:08    15     13     56.69  18.43      53         PM2.5   \n2019-09-05 02:12:08    15     15     56.81  18.39      57         PM2.5   \n2019-09-05 02:13:07    13     12     56.92  18.34      50         PM2.5   \n2019-09-05 02:14:07    13     12     56.99  18.32      50         PM2.5   \n2019-09-05 02:15:07    13     12     57.05  18.29      50         PM2.5   \n2019-09-05 02:16:07    13     13     57.10  18.28      53         PM2.5   \n2019-09-05 02:17:07    13     13     57.14  18.27      53         PM2.5   \n2019-09-05 02:18:07    13     12     57.17  18.26      50         PM2.5   \n2019-09-05 02:19:07    13     13     57.22  18.24      53         PM2.5   \n2019-09-05 02:20:06    11     10     57.21  18.23      42         PM2.5   \n2019-09-05 02:21:06    13     11     57.19  18.21      46         PM2.5   \n2019-09-05 02:22:06    12     10     57.18  18.19      42         PM2.5   \n2019-09-05 02:23:06    10     10     57.22  18.19      42         PM2.5   \n2019-09-05 02:24:05    11     10     57.24  18.17      42         PM2.5   \n2019-09-05 02:25:05    11     11     57.27  18.16      46         PM2.5   \n2019-09-05 02:26:05    11     10     57.34  18.15      42         PM2.5   \n2019-09-05 02:27:05    12     11     57.40  18.12      46         PM2.5   \n2019-09-05 02:28:05    10      9     57.45  18.11      38         PM2.5   \n2019-09-05 02:29:05    10      9     57.53  18.07      38         PM2.5   \n2019-09-05 02:30:04    11     11     57.59  18.05      46         PM2.5   \n2019-09-05 02:31:05    10      9     57.63  18.01      38         PM2.5   \n2019-09-05 02:32:05    11     11     57.69  17.98      46         PM2.5   \n2019-09-05 02:33:05    12      9     57.79  17.95      38         PM2.5   \n2019-09-05 02:34:04     6      6     57.84  17.92      25         PM2.5   \n2019-09-05 02:35:04     8      8     57.96  17.87      33         PM2.5   \n2019-09-05 02:36:04     7      7     57.99  17.84      29         PM2.5   \n2019-09-05 02:37:04     7      7     58.12  17.80      29         PM2.5   \n\n                      PM10_avg  PM2.5_avg  US_AQI_avg  \nTime                                                   \n2019-01-02 18:35:00  54.283019  51.301887  135.679245  \n2019-01-02 18:36:00  54.773585  51.660377  136.528302  \n2019-01-02 18:37:00  55.339623  52.094340  137.490566  \n2019-01-02 18:38:00  55.735849  52.396226  138.226415  \n2019-01-02 18:39:00  56.226415  52.792453  139.037736  \n2019-01-02 18:40:00  56.716981  53.169811  139.962264  \n2019-01-02 18:41:00  57.150943  53.452830  140.660377  \n2019-01-02 18:42:00  57.603774  53.754717  141.320755  \n2019-01-02 18:43:00  57.962264  54.075472  142.094340  \n2019-01-02 18:44:00  58.433962  54.452830  143.018868  \n2019-01-02 18:45:00  58.849057  54.754717  143.754717  \n2019-01-02 18:46:00  59.188679  55.018868  144.415094  \n2019-01-02 18:47:00  59.277778  55.018519  144.500000  \n2019-09-05 01:51:10  16.000000  14.000000   55.000000  \n2019-09-05 01:52:10  16.000000  15.000000   57.000000  \n2019-09-05 01:53:10  16.000000  15.000000   57.000000  \n2019-09-05 01:54:10  16.250000  15.250000   57.500000  \n2019-09-05 01:55:10  16.000000  15.200000   57.400000  \n2019-09-05 01:56:09  15.833333  14.833333   56.666667  \n2019-09-05 01:57:09  15.714286  14.714286   56.428571  \n2019-09-05 01:58:09  15.750000  14.750000   56.500000  \n2019-09-05 01:59:09  16.000000  15.000000   57.000000  \n2019-09-05 02:00:09  15.900000  15.000000   57.000000  \n2019-09-05 02:01:09  15.818182  14.909091   56.818182  \n2019-09-05 02:02:09  15.666667  14.750000   56.500000  \n2019-09-05 02:03:09  15.923077  14.923077   56.846154  \n2019-09-05 02:04:09  15.857143  14.857143   56.714286  \n2019-09-05 02:05:08  15.733333  14.800000   56.600000  \n2019-09-05 02:06:08  15.625000  14.687500   56.375000  \n2019-09-05 02:07:08  15.529412  14.588235   56.176471  \n2019-09-05 02:08:08  15.444444  14.444444   55.833333  \n2019-09-05 02:09:08  15.368421  14.368421   55.684211  \n2019-09-05 02:10:08  15.250000  14.250000   55.400000  \n2019-09-05 02:11:08  15.238095  14.190476   55.285714  \n2019-09-05 02:12:08  15.227273  14.227273   55.363636  \n2019-09-05 02:13:07  15.130435  14.130435   55.130435  \n2019-09-05 02:14:07  15.041667  14.041667   54.916667  \n2019-09-05 02:15:07  14.960000  13.960000   54.720000  \n2019-09-05 02:16:07  14.884615  13.923077   54.653846  \n2019-09-05 02:17:07  14.814815  13.888889   54.592593  \n2019-09-05 02:18:07  14.750000  13.821429   54.428571  \n2019-09-05 02:19:07  14.689655  13.793103   54.379310  \n2019-09-05 02:20:06  14.566667  13.666667   53.966667  \n2019-09-05 02:21:06  14.516129  13.580645   53.709677  \n2019-09-05 02:22:06  14.437500  13.468750   53.343750  \n2019-09-05 02:23:06  14.303030  13.363636   53.000000  \n2019-09-05 02:24:05  14.205882  13.264706   52.676471  \n2019-09-05 02:25:05  14.114286  13.200000   52.485714  \n2019-09-05 02:26:05  14.027778  13.111111   52.194444  \n2019-09-05 02:27:05  13.972973  13.054054   52.027027  \n2019-09-05 02:28:05  13.868421  12.947368   51.657895  \n2019-09-05 02:29:05  13.769231  12.846154   51.307692  \n2019-09-05 02:30:04  13.700000  12.800000   51.175000  \n2019-09-05 02:31:05  13.609756  12.707317   50.853659  \n2019-09-05 02:32:05  13.547619  12.666667   50.738095  \n2019-09-05 02:33:05  13.511628  12.581395   50.441860  \n2019-09-05 02:34:04  13.340909  12.431818   49.863636  \n2019-09-05 02:35:04  13.222222  12.333333   49.488889  \n2019-09-05 02:36:04  13.086957  12.217391   49.043478  \n2019-09-05 02:37:04  12.957447  12.106383   48.617021  \n                     PM10  PM2.5  Humidity   Temp  US_AQI HighestPMType  \\\nTime                                                                      \n2020-06-14 18:40:32     1      1     65.29  17.68       4         PM2.5   \n2020-06-14 18:41:32     1      1     65.01  17.68       4         PM2.5   \n2020-06-14 18:42:32     0      0     64.65  17.66       0          PM10   \n2020-06-14 18:43:32     2      2     64.42  17.66       8         PM2.5   \n2020-06-14 18:44:32     0      0     64.05  17.66       0          PM10   \n\n                     PM10_avg  PM2.5_avg  US_AQI_avg  \nTime                                                  \n2020-06-14 18:40:32  2.470588   1.941176    8.117647  \n2020-06-14 18:41:32  2.388889   1.888889    7.888889  \n2020-06-14 18:42:32  2.263158   1.789474    7.473684  \n2020-06-14 18:43:32  2.250000   1.800000    7.500000  \n2020-06-14 18:44:32  2.142857   1.714286    7.142857  \n"}],"source":["# Setting the time as index so we can use the offset windows option when rolling\n","df_allmyData = df_allmyData.set_index('Time')\n","\n","# 1 Hour rolling averages\n","df_allmyData['PM10_avg'] = df_allmyData.rolling(window='60min')['PM10'].mean()\n","df_allmyData['PM2.5_avg'] = df_allmyData.rolling(window='60min')['PM2.5'].mean()\n","df_allmyData['US_AQI_avg'] = df_allmyData.rolling(window='60min')['US_AQI'].mean()\n","\n","# Seems good to analyse now\n","print(df_allmyData.dtypes)\n","print(df_allmyData.head())\n","print(df_allmyData[9760:9820])\n","print(df_allmyData.tail())"]},{"cell_type":"code","execution_count":646,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\nWARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\nWARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\nWARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\nWARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\nWARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"}],"source":["# Public avaliable datasets\n","\n","gPath = Path('../govtData')\n","list_govt_df_names = [item.name for item in sorted(gPath.glob('*.xls'))]\n","list_govt_df_path = [os.path.join(gPath, item) for item in list_govt_df_names]\n","\n","df_nParra = pd.read_excel(list_govt_df_path[0], header=2, parse_dates=[['Date', 'Time']], index_col=0)\n","df_prospect = pd.read_excel(list_govt_df_path[1], header=2, parse_dates=[['Date', 'Time']], index_col=0)\n","df_richmond = pd.read_excel(list_govt_df_path[2], header=2, parse_dates=[['Date', 'Time']], index_col=0)\n","df_rouseHill = pd.read_excel(list_govt_df_path[3], header=2, parse_dates=[['Date', 'Time']], index_col=0)\n","df_stMarys = pd.read_excel(list_govt_df_path[4], header=2, parse_dates=[['Date', 'Time']], index_col=0)\n","df_westSydAQI_noVinyard = pd.read_excel(list_govt_df_path[5], header=2, parse_dates=[['Date', 'Time']], index_col=0)"]},{"cell_type":"code","execution_count":643,"metadata":{},"outputs":[],"source":["# Couldn't change the headings as I wanted during the reading excel bit so it got bumped to here\n","# This is where only richmond and rouse hill was discovered to have rainfall in their datasets.\n","\n","govt_headings = ['WDR', 'Temp', 'WSP', 'PM10', 'PM2.5', 'Humid', 'Solar', 'Rain']\n","pattern = re.compile('[A-z]+[_]')\n","siteNames = [pattern.findall(item) for item in list_govt_df_names]\n","siteNames_flat = [item for sublist in siteNames for item in sublist]\n","list_govt_headings = [site+head for site in siteNames_flat for head in govt_headings]\n","\n","headings_nParra = list_govt_headings[0:7] \n","headings_prospect = list_govt_headings[8:15]\n","headings_richmond = list_govt_headings[16:24]\n","headings_rouseHill = list_govt_headings[25:32]\n","headings_stMarys = list_govt_headings[33:40]\n","\n","df_nParra.columns = headings_nParra\n","df_prospect.columns = headings_prospect\n","df_richmond.columns = headings_richmond\n","df_rouseHill.columns = headings_rouseHill\n","df_stMarys.columns = headings_stMarys\n","df_westSydAQI_noVinyard.columns = ['richmond_AQI', 'stMarys_AQI', 'nParra_AQI', 'prospect_AQI', 'rouseHill_AQI']"]},{"cell_type":"code","execution_count":651,"metadata":{},"outputs":[],"source":["dict_df = {\n","    'allmyData': df_allmyData,\n","    'nParra': df_nParra,\n","    'prospect': df_prospect,\n","    'richmond': df_richmond,\n","    'rouseHill': df_rouseHill,\n","    'stMarys': df_stMarys,\n","    'westSydAQI': df_westSydAQI_noVinyard\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Choose to NOT dropNA for the government datasets, due to meaning found "]},{"cell_type":"code","execution_count":647,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"RICHMOND AQI hourly AQI [index]            12686\nST MARYS AQI hourly AQI [index]            12743\nPARRAMATTA NORTH AQI hourly AQI [index]    12768\nPROSPECT AQI hourly AQI [index]            12652\nROUSE HILL AQI hourly AQI [index]           9265\ndtype: int64"},"metadata":{},"execution_count":647}],"source":["df_nParra.count()\n","df_prospect.count()\n","df_richmond.count()\n","df_rouseHill.count()\n","df_stMarys.count()\n","df_westSydAQI_noVinyard.count()"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>4. Exploratory data analysis</h1>\n","\n","This is the main part of the project. Include code, plots, and detailed explanation of your analysis of the data. Be sure to include enough detail so that anyone can follow and understand what you are doing.\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Questions to ask</h2>\n","<li> What's a week look like? Maybe heatmaps? </li>\n","<li> How does each of the PM stats compare to eachother? </li>\n","<li> How does the meterological stats compare to eachother? </li>\n","<li> Does wind, rain or other meterological measures have a correlation with the air quality indicators? </li>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>5. Results/Insights</h1>\n","\n","Discuss any non-trivial result or insight into the problem stemming from your analysis.\n","\n","<b>Create as many code, markdown and raw cells as needed</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>6. In hindsight...</h1>\n","\n","In this section you should reflect on your work and what you've learned. In particular you should include:\n","\n","<ul>\n","    <li> a discussion of the most challenging aspect of the data analysis and if/how you overcame the challenge.</li>\n","    <li> a discussion of any programming technique and/or reference you found particularly useful or helpful for your project.</li>\n","    <li> an assessment of the outcome of the study in relation to the original goals (i.e., have the goals been reached, or did you have to reassess the goals during the project, and if so why?).</li>\n","    <li> a discussion of what new, or surprising knowledge or insight into the problem you've gained by conducting the study.</li>\n","    <li> a discussion of whether you would approach the problem differently if given an opportunity to redo the work, and any advice they would give to someone who would want to work on a similar problem.</li>\n","    <li> a discussion of how your analysis could be improved or extended in future work.</li>\n","\n","</ul>"]},{"cell_type":"markdown","metadata":{},"source":["In hindsight, the time spent manually changing the filenames was wasted due to how data was read. "]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"height:5px;border:none;color:#333;background-color:#333;\" />\n","<h1>Appendix</h1>\n","<p> Image of US AQI calculation </p>\n","<a href=\"https://forum.airnowtech.org/t/the-aqi-equation/169\"><img src=\"https://puu.sh/FWnlz/f37ea1e65d.png\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["The adventure into the air quality data I've gathered. \n","My non-scientific and possible real-world-case approach to how I went through the analysais of my gathered dataset.\n","\n","For context, this dataset is gathered by a Kaiterra LaserEgg model LE-200 that is placed on my work desk at my home. Not in scientific conditions, as the layout of my house can describe this [Insert quick layout]\n","\n"," "]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.7-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":2}